{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Objective\" data-toc-modified-id=\"Objective-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Objective</a></span></li><li><span><a href=\"#Used-Python-Libraries\" data-toc-modified-id=\"Used-Python-Libraries-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Used Python Libraries</a></span></li><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Load Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Chats-Data\" data-toc-modified-id=\"Chats-Data-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Chats Data</a></span></li><li><span><a href=\"#Talking-Points-Data\" data-toc-modified-id=\"Talking-Points-Data-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Talking Points Data</a></span></li><li><span><a href=\"#Merging-Data----Do-not-do-this-for-now-since-we-end-up-with-few-exemplars\" data-toc-modified-id=\"Merging-Data----Do-not-do-this-for-now-since-we-end-up-with-few-exemplars-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Merging Data -- Do not do this for now since we end up with few exemplars</a></span></li></ul></li><li><span><a href=\"#A-First-Glance-at-Transcripts\" data-toc-modified-id=\"A-First-Glance-at-Transcripts-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>A First Glance at Transcripts</a></span></li><li><span><a href=\"#A-First-Glance-at-Chats\" data-toc-modified-id=\"A-First-Glance-at-Chats-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>A First Glance at Chats</a></span></li><li><span><a href=\"#Pre-Trained-Sentence-Encoder\" data-toc-modified-id=\"Pre-Trained-Sentence-Encoder-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Pre-Trained Sentence Encoder</a></span><ul class=\"toc-item\"><li><span><a href=\"#Example-of-Using-Encoder\" data-toc-modified-id=\"Example-of-Using-Encoder-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Example of Using Encoder</a></span></li></ul></li><li><span><a href=\"#Data-Processing\" data-toc-modified-id=\"Data-Processing-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Data Processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Processing-Call-Transcripts\" data-toc-modified-id=\"Processing-Call-Transcripts-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Processing Call Transcripts</a></span><ul class=\"toc-item\"><li><span><a href=\"#Example-of-Processed-Transcript-Data\" data-toc-modified-id=\"Example-of-Processed-Transcript-Data-7.1.1\"><span class=\"toc-item-num\">7.1.1&nbsp;&nbsp;</span>Example of Processed Transcript Data</a></span></li></ul></li><li><span><a href=\"#Processing-Chats\" data-toc-modified-id=\"Processing-Chats-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Processing Chats</a></span><ul class=\"toc-item\"><li><span><a href=\"#Example-of-Processed-Chat-Data\" data-toc-modified-id=\"Example-of-Processed-Chat-Data-7.2.1\"><span class=\"toc-item-num\">7.2.1&nbsp;&nbsp;</span>Example of Processed Chat Data</a></span></li></ul></li></ul></li><li><span><a href=\"#Analyzing-Processed-Data\" data-toc-modified-id=\"Analyzing-Processed-Data-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Analyzing Processed Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Analyzing-Transcript\" data-toc-modified-id=\"Analyzing-Transcript-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Analyzing Transcript</a></span></li><li><span><a href=\"#Analyzing-Chats\" data-toc-modified-id=\"Analyzing-Chats-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>Analyzing Chats</a></span></li></ul></li><li><span><a href=\"#Interactive-Visualization-of-Results\" data-toc-modified-id=\"Interactive-Visualization-of-Results-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Interactive Visualization of Results</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "This project will prototype a screening tool to:\n",
    "\n",
    "    * identify calls where customer agents speak about offers/recommendations they are able to see as talking points in the customer panel during a call;\n",
    "    * determine whether the \"discussed\" botton (supposedly pressed by agents) describes accurately if a recommendation was pitched or not.\n",
    "    \n",
    "Two data tables will be used:\n",
    "\n",
    "    * a table containing information about the call and the call transcripts \n",
    "    * a table containing information about discussion of talking points\n",
    "    \n",
    "<img src=\"xxx.png\" width=800 /> ![](one_pager_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Used Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text #needed to avoid crashes\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import ray\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "We use data downloaded from Kaggle ([Ubuntu Dialogue Corpus](https://www.kaggle.com/rtatman/ubuntu-dialogue-corpus?ref=hackernoon.com) project)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://registry.opendata.aws/topical-chat-enriched/\n",
    "\n",
    "import boto3\n",
    "import os\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "\n",
    "def download_all_files():\n",
    "    #initiate s3 resource\n",
    "    s3 = boto3.resource('s3', config=Config(signature_version=UNSIGNED))\n",
    "    # select bucket\n",
    "    my_bucket = s3.Bucket('enriched-topical-chat')\n",
    "    # download file into current directory\n",
    "    for s3_object in my_bucket.objects.all():\n",
    "        filename = s3_object.key\n",
    "        my_bucket.download_file(s3_object.key, filename)\n",
    "        \n",
    "download_all_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv *.json data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>config</th>\n",
       "      <th>content</th>\n",
       "      <th>conversation_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t_bde29ce2-4153-4056-9eb7-f4ad710505fe</th>\n",
       "      <td>C</td>\n",
       "      <td>[{'message': ['Are you a fan of Google or Micr...</td>\n",
       "      <td>{'agent_1': 'Excellent', 'agent_2': 'Excellent'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_1abc9c37-387d-4013-8691-88ef8c010e58</th>\n",
       "      <td>B</td>\n",
       "      <td>[{'message': ['do you like dance?'], 'agent': ...</td>\n",
       "      <td>{'agent_1': 'Excellent', 'agent_2': 'Excellent'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_1a600621-5ad4-409c-a812-bc0b2bb03aa6</th>\n",
       "      <td>C</td>\n",
       "      <td>[{'message': ['Hey what's up do use Google ver...</td>\n",
       "      <td>{'agent_1': 'Excellent', 'agent_2': 'Excellent'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_01269680-99c3-4ab4-9df3-23901e0623c9</th>\n",
       "      <td>C</td>\n",
       "      <td>[{'message': ['Hi!', 'do you like to dance?'],...</td>\n",
       "      <td>{'agent_1': 'Excellent', 'agent_2': 'Excellent'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_c4f84350-a9e8-4928-bde8-5193b62388e0</th>\n",
       "      <td>B</td>\n",
       "      <td>[{'message': ['do you like dance?'], 'agent': ...</td>\n",
       "      <td>{'agent_1': 'Excellent', 'agent_2': 'Excellent'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       config  \\\n",
       "t_bde29ce2-4153-4056-9eb7-f4ad710505fe      C   \n",
       "t_1abc9c37-387d-4013-8691-88ef8c010e58      B   \n",
       "t_1a600621-5ad4-409c-a812-bc0b2bb03aa6      C   \n",
       "t_01269680-99c3-4ab4-9df3-23901e0623c9      C   \n",
       "t_c4f84350-a9e8-4928-bde8-5193b62388e0      B   \n",
       "\n",
       "                                                                                  content  \\\n",
       "t_bde29ce2-4153-4056-9eb7-f4ad710505fe  [{'message': ['Are you a fan of Google or Micr...   \n",
       "t_1abc9c37-387d-4013-8691-88ef8c010e58  [{'message': ['do you like dance?'], 'agent': ...   \n",
       "t_1a600621-5ad4-409c-a812-bc0b2bb03aa6  [{'message': ['Hey what's up do use Google ver...   \n",
       "t_01269680-99c3-4ab4-9df3-23901e0623c9  [{'message': ['Hi!', 'do you like to dance?'],...   \n",
       "t_c4f84350-a9e8-4928-bde8-5193b62388e0  [{'message': ['do you like dance?'], 'agent': ...   \n",
       "\n",
       "                                                                     conversation_rating  \n",
       "t_bde29ce2-4153-4056-9eb7-f4ad710505fe  {'agent_1': 'Excellent', 'agent_2': 'Excellent'}  \n",
       "t_1abc9c37-387d-4013-8691-88ef8c010e58  {'agent_1': 'Excellent', 'agent_2': 'Excellent'}  \n",
       "t_1a600621-5ad4-409c-a812-bc0b2bb03aa6  {'agent_1': 'Excellent', 'agent_2': 'Excellent'}  \n",
       "t_01269680-99c3-4ab4-9df3-23901e0623c9  {'agent_1': 'Excellent', 'agent_2': 'Excellent'}  \n",
       "t_c4f84350-a9e8-4928-bde8-5193b62388e0  {'agent_1': 'Excellent', 'agent_2': 'Excellent'}  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_json('data/train.json').T\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'message': [\"Hey what's up do use Google very often?I really love the company and was surprised to hear that it was founded back in 1998.\"],\n",
       "  'agent': 'agent_1',\n",
       "  'segmented_annotations': [{'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'wiki',\n",
       "     'section': 'FS1',\n",
       "     'start_index': 479,\n",
       "     'end_index': 553,\n",
       "     'score': 0.27}}],\n",
       "  'gt_turn_ks': {'ds': 'wiki',\n",
       "   'section': 'FS1',\n",
       "   'start_index': 479,\n",
       "   'end_index': 553,\n",
       "   'score': 0.27}},\n",
       " {'message': ['i think everyone must use it daily!',\n",
       "   'its become ingrained in every day life'],\n",
       "  'agent': 'agent_2',\n",
       "  'segmented_annotations': [{'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'wiki',\n",
       "     'section': 'FS2',\n",
       "     'start_index': 558,\n",
       "     'end_index': 778,\n",
       "     'score': 0.03}},\n",
       "   {'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts',\n",
       "     'section': 'FS3',\n",
       "     'index': 1,\n",
       "     'score': 0.12}}],\n",
       "  'gt_turn_ks': {'ds': 'fun_facts',\n",
       "   'section': 'FS3',\n",
       "   'index': 1,\n",
       "   'score': 0.11}},\n",
       " {'message': ['Agreed.',\n",
       "   'The Google headquarters in Mountain View California is nicknamed the Google Plex.'],\n",
       "  'agent': 'agent_1',\n",
       "  'segmented_annotations': [{'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts', 'section': 'FS3', 'index': 4, 'score': 0.0}},\n",
       "   {'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'wiki',\n",
       "     'section': 'FS1',\n",
       "     'start_index': 554,\n",
       "     'end_index': 710,\n",
       "     'score': 0.56}}],\n",
       "  'gt_turn_ks': {'ds': 'wiki',\n",
       "   'section': 'FS1',\n",
       "   'start_index': 554,\n",
       "   'end_index': 710,\n",
       "   'score': 0.53}},\n",
       " {'message': ['thats funny.',\n",
       "   'The current CEO is Sundar Pichai, i didnt know Larry Page was replaced'],\n",
       "  'agent': 'agent_2',\n",
       "  'segmented_annotations': [{'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts', 'section': 'FS3', 'index': 4, 'score': 0.0}},\n",
       "   {'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'wiki',\n",
       "     'section': 'FS1',\n",
       "     'start_index': 945,\n",
       "     'end_index': 1040,\n",
       "     'score': 0.66}}],\n",
       "  'gt_turn_ks': {'ds': 'wiki',\n",
       "   'section': 'FS1',\n",
       "   'start_index': 945,\n",
       "   'end_index': 1040,\n",
       "   'score': 0.58}},\n",
       " {'message': [\"Oh yeah I didn't know that either.\",\n",
       "   'I also want to go to google Plex to see the goats who mow their lawn by eating it.'],\n",
       "  'agent': 'agent_1',\n",
       "  'segmented_annotations': [{'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts', 'section': 'FS2', 'index': 3, 'score': 0.02}},\n",
       "   {'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts',\n",
       "     'section': 'FS1',\n",
       "     'index': 2,\n",
       "     'score': 0.44}}],\n",
       "  'gt_turn_ks': {'ds': 'fun_facts',\n",
       "   'section': 'FS1',\n",
       "   'index': 2,\n",
       "   'score': 0.37}},\n",
       " {'message': ['say what now??', 'they have that?', '?'],\n",
       "  'agent': 'agent_2',\n",
       "  'segmented_annotations': [{'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts', 'section': 'FS3', 'index': 4, 'score': 0.0}},\n",
       "   {'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts', 'section': 'FS2', 'index': 2, 'score': 0.12}},\n",
       "   {'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts', 'section': 'FS3', 'index': 4, 'score': 0.0}}],\n",
       "  'gt_turn_ks': {'ds': 'fun_facts',\n",
       "   'section': 'FS2',\n",
       "   'index': 2,\n",
       "   'score': 0.07}},\n",
       " {'message': ['Yeah apparently lol!',\n",
       "   'They do that instead of hiring people to mow!'],\n",
       "  'agent': 'agent_1',\n",
       "  'segmented_annotations': [{'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts', 'section': 'FS3', 'index': 4, 'score': 0.0}},\n",
       "   {'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts',\n",
       "     'section': 'FS1',\n",
       "     'index': 2,\n",
       "     'score': 0.55}}],\n",
       "  'gt_turn_ks': {'ds': 'fun_facts',\n",
       "   'section': 'FS1',\n",
       "   'index': 2,\n",
       "   'score': 0.42}},\n",
       " {'message': ['thats both funny and i guess imaginative.',\n",
       "   'leave it to a huge tech company to employ actual goats!'],\n",
       "  'agent': 'agent_2',\n",
       "  'segmented_annotations': [{'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts', 'section': 'FS3', 'index': 0, 'score': 0.02}},\n",
       "   {'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts',\n",
       "     'section': 'FS1',\n",
       "     'index': 2,\n",
       "     'score': 0.17}}],\n",
       "  'gt_turn_ks': {'ds': 'fun_facts',\n",
       "   'section': 'FS1',\n",
       "   'index': 2,\n",
       "   'score': 0.13}},\n",
       " {'message': ['Yeah exactly I am sure they are cheaper.',\n",
       "   \"One thing I bet they couldn't exploit is fish.\",\n",
       "   'I think fish are so cool there is actually a breed of jellyfish that is immortal.'],\n",
       "  'agent': 'agent_1',\n",
       "  'segmented_annotations': [{'da': '<NoDialogAct>',\n",
       "    'gt_ks': {'ds': 'wiki',\n",
       "     'section': 'FS2',\n",
       "     'start_index': 289,\n",
       "     'end_index': 373,\n",
       "     'score': 0.05}},\n",
       "   {'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts', 'section': 'FS2', 'index': 2, 'score': 0.2}},\n",
       "   {'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts', 'section': 'FS2', 'index': 3, 'score': 0.8}}],\n",
       "  'gt_turn_ks': {'ds': 'fun_facts',\n",
       "   'section': 'FS2',\n",
       "   'index': 3,\n",
       "   'score': 0.53}},\n",
       " {'message': ['i had rememered hearing about that before.',\n",
       "   'Immortatlity is wasted on a jellyfish haha.',\n",
       "   'did you know a seahorse is the only fish that has an actual neck?'],\n",
       "  'agent': 'agent_2',\n",
       "  'segmented_annotations': [{'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts', 'section': 'FS3', 'index': 3, 'score': 0.06}},\n",
       "   {'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts', 'section': 'FS2', 'index': 3, 'score': 0.39}},\n",
       "   {'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts',\n",
       "     'section': 'FS2',\n",
       "     'index': 2,\n",
       "     'score': 0.79}}],\n",
       "  'gt_turn_ks': {'ds': 'fun_facts',\n",
       "   'section': 'FS2',\n",
       "   'index': 2,\n",
       "   'score': 0.56}},\n",
       " {'message': ['That is so funny I guess I never considered a seahorse a fish.',\n",
       "   'The black swallower fish sounds a lot like a snake because it can eat pray that is so large.'],\n",
       "  'agent': 'agent_1',\n",
       "  'segmented_annotations': [{'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts', 'section': 'FS2', 'index': 2, 'score': 0.55}},\n",
       "   {'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts',\n",
       "     'section': 'FS2',\n",
       "     'index': 0,\n",
       "     'score': 0.47000000000000003}}],\n",
       "  'gt_turn_ks': {'ds': 'fun_facts',\n",
       "   'section': 'FS2',\n",
       "   'index': 0,\n",
       "   'score': 0.44}},\n",
       " {'message': ['i guess they live up to their name then!'],\n",
       "  'agent': 'agent_2',\n",
       "  'segmented_annotations': [{'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts',\n",
       "     'section': 'FS1',\n",
       "     'index': 2,\n",
       "     'score': 0.14}}],\n",
       "  'gt_turn_ks': {'ds': 'fun_facts',\n",
       "   'section': 'FS1',\n",
       "   'index': 2,\n",
       "   'score': 0.14}},\n",
       " {'message': ['It seems they do.',\n",
       "   \"I also didn't know that there was a difference with how freshwater and saltwater fish drink.\"],\n",
       "  'agent': 'agent_1',\n",
       "  'segmented_annotations': [{'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'wiki',\n",
       "     'section': 'FS1',\n",
       "     'start_index': 479,\n",
       "     'end_index': 553,\n",
       "     'score': 0.07}},\n",
       "   {'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts',\n",
       "     'section': 'FS2',\n",
       "     'index': 1,\n",
       "     'score': 0.55}}],\n",
       "  'gt_turn_ks': {'ds': 'fun_facts',\n",
       "   'section': 'FS2',\n",
       "   'index': 1,\n",
       "   'score': 0.51}},\n",
       " {'message': ['thats crazy.',\n",
       "   'i wonder why fresh water ones only use osmosis?'],\n",
       "  'agent': 'agent_2',\n",
       "  'segmented_annotations': [{'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts', 'section': 'FS3', 'index': 4, 'score': 0.0}},\n",
       "   {'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts',\n",
       "     'section': 'FS2',\n",
       "     'index': 1,\n",
       "     'score': 0.31}}],\n",
       "  'gt_turn_ks': {'ds': 'fun_facts',\n",
       "   'section': 'FS2',\n",
       "   'index': 1,\n",
       "   'score': 0.27}},\n",
       " {'message': [\"Yeah and saltwater fish are lucky because they can do that and drink through their mouth's.\"],\n",
       "  'agent': 'agent_1',\n",
       "  'segmented_annotations': [{'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts',\n",
       "     'section': 'FS2',\n",
       "     'index': 1,\n",
       "     'score': 0.47000000000000003}}],\n",
       "  'gt_turn_ks': {'ds': 'fun_facts',\n",
       "   'section': 'FS2',\n",
       "   'index': 1,\n",
       "   'score': 0.47000000000000003}},\n",
       " {'message': ['seems like fresh water fish got the short end of the stick with that one.',\n",
       "   'Have you ever been to a cat cafe?'],\n",
       "  'agent': 'agent_2',\n",
       "  'segmented_annotations': [{'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts', 'section': 'FS2', 'index': 1, 'score': 0.26}},\n",
       "   {'da': '<PropQ>',\n",
       "    'gt_ks': {'ds': 'wiki',\n",
       "     'section': 'FS3',\n",
       "     'start_index': 384,\n",
       "     'end_index': 460,\n",
       "     'score': 0.28}}],\n",
       "  'gt_turn_ks': {'ds': 'fun_facts',\n",
       "   'section': 'FS2',\n",
       "   'index': 1,\n",
       "   'score': 0.21}},\n",
       " {'message': ['I have never been to a cat cafe no, what about you?',\n",
       "   'Seems like they are popular in Japan and Taiwan.'],\n",
       "  'agent': 'agent_1',\n",
       "  'segmented_annotations': [{'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'wiki',\n",
       "     'section': 'FS3',\n",
       "     'start_index': 384,\n",
       "     'end_index': 460,\n",
       "     'score': 0.26}},\n",
       "   {'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts',\n",
       "     'section': 'FS3',\n",
       "     'index': 0,\n",
       "     'score': 0.39}}],\n",
       "  'gt_turn_ks': {'ds': 'fun_facts',\n",
       "   'section': 'FS3',\n",
       "   'index': 0,\n",
       "   'score': 0.4}},\n",
       " {'message': ['no but I would love to!',\n",
       "   'paying hourly to hang out with adorable cats?',\n",
       "   'im in!'],\n",
       "  'agent': 'agent_2',\n",
       "  'segmented_annotations': [{'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'wiki',\n",
       "     'section': 'FS2',\n",
       "     'start_index': 779,\n",
       "     'end_index': 890,\n",
       "     'score': 0.04}},\n",
       "   {'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts', 'section': 'FS3', 'index': 0, 'score': 0.37}},\n",
       "   {'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'wiki',\n",
       "     'section': 'FS2',\n",
       "     'start_index': 558,\n",
       "     'end_index': 778,\n",
       "     'score': 0.03}}],\n",
       "  'gt_turn_ks': {'ds': 'fun_facts',\n",
       "   'section': 'FS3',\n",
       "   'index': 0,\n",
       "   'score': 0.33}},\n",
       " {'message': ['Yeah that would be a lot of fun.',\n",
       "   \"I didn't realize that cats sleep so much.\",\n",
       "   'Must be nice.'],\n",
       "  'agent': 'agent_1',\n",
       "  'segmented_annotations': [{'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts', 'section': 'FS2', 'index': 4, 'score': 0.04}},\n",
       "   {'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts', 'section': 'FS3', 'index': 0, 'score': 0.17}},\n",
       "   {'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts',\n",
       "     'section': 'FS2',\n",
       "     'index': 4,\n",
       "     'score': 0.04}}],\n",
       "  'gt_turn_ks': {'ds': 'fun_facts',\n",
       "   'section': 'FS3',\n",
       "   'index': 0,\n",
       "   'score': 0.11}},\n",
       " {'message': ['i guess thats where the phrase \"cat nap\" comes from'],\n",
       "  'agent': 'agent_2',\n",
       "  'segmented_annotations': [{'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'wiki',\n",
       "     'section': 'FS3',\n",
       "     'start_index': 384,\n",
       "     'end_index': 460,\n",
       "     'score': 0.19}}],\n",
       "  'gt_turn_ks': {'ds': 'wiki',\n",
       "   'section': 'FS3',\n",
       "   'start_index': 384,\n",
       "   'end_index': 460,\n",
       "   'score': 0.19}},\n",
       " {'message': ['Oh yeah I guess so ha ha.',\n",
       "   \"There's even a town in Alaska that has a mayor cat.\"],\n",
       "  'agent': 'agent_1',\n",
       "  'segmented_annotations': [{'da': '<NoDialogAct>',\n",
       "    'gt_ks': {'ds': 'fun_facts', 'section': 'FS3', 'index': 2, 'score': 0.03}},\n",
       "   {'da': '<Statement>',\n",
       "    'gt_ks': {'ds': 'fun_facts',\n",
       "     'section': 'FS3',\n",
       "     'index': 3,\n",
       "     'score': 0.56}}],\n",
       "  'gt_turn_ks': {'ds': 'fun_facts',\n",
       "   'section': 'FS3',\n",
       "   'index': 3,\n",
       "   'score': 0.34}}]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_tmp = train_df.iloc[2]['content']\n",
    "cont_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/alexa/Topical-Chat/blob/master/src/wiki/wiki.json\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"data/alexa/wiki/wiki.json\", \"r\") as f:\n",
    "    wiki_data = json.load(f)\n",
    "    shortened_wiki_lead_section = wiki_data['shortened_wiki_lead_section']\n",
    "    summarized_wiki_lead_section = wiki_data['summarized_wiki_lead_section']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "talking_points = list(shortened_wiki_lead_section.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A horror film is a film that seeks to elicit fear. Initially inspired by literature from authors like Edgar Allan Poe, Bram Stoker, and Mary Shelley, horror has existed as a film genre for more than a century. The macabre and the supernatural are frequent themes. Horror may also overlap with the fantasy, supernatural fiction, and thriller genres.',\n",
       " 'A soundtrack, also written sound track, can be recorded music accompanying and synchronized to the images of a motion picture, book, television program, or video game; a commercially released soundtrack album of music as featured in the soundtrack of a film, video, or television presentation; or the physical area of a film that contains the synchronized recorded sound.',\n",
       " 'An album is a collection of audio recordings issued as a collection on compact disc (CD), vinyl, audio tape, or another medium. Albums of recorded music were developed in the early 20th century as individual 78-rpm records collected in a bound book resembling a photograph album; this format evolved after 1948 into single vinyl LP records  played at \\u200b33 1⁄3 rpm. Vinyl LPs are still issued, though album sales in the 21st-century have mostly focused on CD and MP3 formats. The audio cassette was a format used alongside vinyl from the 1970s into the first decade of the 2000s.',\n",
       " 'The president is a common title for the head of state in most republics. In politics, president is a title given to leaders of republican states.\\nThe functions exercised by a president vary according to the form of government. In parliamentary republics, they are limited to those of the head of state, and are thus largely ceremonial. In presidential and semi-presidential republics, the role of the president is more prominent, encompassing also (in most cases) the functions of the head of government. In authoritarian regimes, a dictator or leader of a one-party state may also be called a president.',\n",
       " 'The United States Senate is the upper chamber of the United States Congress, which along with the United States House of Representatives—the lower chamber—comprises the legislature of the United States.\\nThe composition and powers of the Senate are established by Article One of the United States Constitution.  The Senate is composed of senators, each of whom represents a single state in its entirety, with each state being equally represented by two senators, regardless of its population, serving staggered terms of six years; with 50 states currently in the Union, there are 100 U.S. Senators. From 1789 until 1913, Senators were appointed by legislatures of the states they represented; following the ratification of the Seventeenth Amendment in 1913, they are now popularly elected.  The Senate chamber is located in the north wing of the Capitol, in Washington, D.C.']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talking_points[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10784, 1)\n"
     ]
    }
   ],
   "source": [
    "chats_datafiles = glob.glob(\"./data/alexa/*.json\")\n",
    "chats_df = pd.concat([pd.read_json(fp).T.drop(['config','conversation_rating'], axis=1) \n",
    "                      for fp in chats_datafiles], ignore_index=True)\n",
    "print(chats_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'message': ['Do you know who Emily Dickson i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'message': ['Did you know the richest superh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'message': ['What arts do you enjoy?', 'Musi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'message': ['Are you familiar with summit me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'message': ['Do you watch soccer?'], 'agent'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0  [{'message': ['Do you know who Emily Dickson i...\n",
       "1  [{'message': ['Did you know the richest superh...\n",
       "2  [{'message': ['What arts do you enjoy?', 'Musi...\n",
       "3  [{'message': ['Are you familiar with summit me...\n",
       "4  [{'message': ['Do you watch soccer?'], 'agent'..."
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Do you know who Emily Dickson is?'],\n",
       " ['Emily Dickinson?',\n",
       "  'The poet?',\n",
       "  'I do!',\n",
       "  '\"Tell all the truth, but tell it slant\" she once said.',\n",
       "  'Do you like her poetry?'],\n",
       " ['Yeah she was an icon she died in 1886 at the tender age of 55.'],\n",
       " ['Though she was reclusive, she lived an interesting 55 years.',\n",
       "  'Do you know much about her life?'],\n",
       " ['I did not unfortunately!',\n",
       "  'I hear over the years she shared at least 250 poems with Susan her close friend before marrying Austin.'],\n",
       " ['Yes.',\n",
       "  'she wrote hundreds and hundreds of poems, but they were locked away in a drawer, and a critic said that there were many arresting phrases, nothing scanned or rhymed properly, and so he declined to help get them published.'],\n",
       " ['Did you kow theres a poem when read normally is depressing but when read backward is uplifting?'],\n",
       " ['Wow!',\n",
       "  \"That is certainly different than Emily's poetry.\",\n",
       "  \"There's such a diversity in poetry.\",\n",
       "  \"It's no surprise, since poetry dates back to prehistorical times.\",\n",
       "  'Did you know some of the first poetry was hunting poetry in Africa?'],\n",
       " ['Yes and and extensively throughout the history of the empire of the Nile, Niger and Volta river valleys.'],\n",
       " ['Yes.',\n",
       "  'Some of the earliest written poetry in Africa is found among Pyramid texts, written during the 25th century, BCE!',\n",
       "  'Of course, poetry spread throughout the world, too.'],\n",
       " ['Wow i did not know that.',\n",
       "  'Edgar Allen Poe received 9.00 for the raven,can you believe that?'],\n",
       " ['Just $9?',\n",
       "  'You know, art, music, and poetry were once Olympic sports?',\n",
       "  'Can you imagine Edgar Allen Poe as an Olympian?'],\n",
       " ['I can not but the fact that those parts of our culture use to be in the Olympics is amazing.',\n",
       "  'They should bring that back.'],\n",
       " ['Yes, poetry does seem to have lost some respect.',\n",
       "  'In the past, the Vikings were warrior-poets, and poetry was considered a gift from Odin himself.'],\n",
       " [\"Now that's interesting.\", 'Homers Odyssey was one of my favorites.'],\n",
       " ['Ah yes!',\n",
       "  \"Quite an epic, isn't it?\",\n",
       "  'And Homer wrote the Iliad, as well.'],\n",
       " ['Bringing back so many memories, i think i might listen to that soon.',\n",
       "  'Demetri Martin wrote a 224 word palindrome poem.'],\n",
       " ['Funny!',\n",
       "  'You really can do so much with poetry!',\n",
       "  \"There's also a poem that's 274 lines, and features about 800 irregularly pronounced English words.\",\n",
       "  \"It's called The Chaos.\",\n",
       "  \"I'd like hear that one read out loud!\"],\n",
       " ['Yeah that seems like the right name for it.',\n",
       "  'Do you listen to or play the piano?'],\n",
       " ['Funny you should ask!',\n",
       "  'I was just going to ask if you knew that they used to call typewriters \"literary pianos\"!',\n",
       "  \"Isn't that funny?\",\n",
       "  'I like to bang on the keyboard every now and then!',\n",
       "  'What about you?'],\n",
       " [\"That's all i do is bang on them while missing the keys i'm aiming for, lol!\",\n",
       "  'Nice chatting with you.'],\n",
       " [\"Good thing you're not playing on an old steam piano!\",\n",
       "  \"They'd hear you for miles around!\",\n",
       "  'Goodbye!'],\n",
       " ['Well maybe not on Mars, haha, Goodbye.']]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ic['message'] for ic in chats_df.iloc[0]['content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To use Kaggle API, first upload your keys. See for more info:\n",
    "https://www.kaggle.com/docs/api to download datasets from kaggle\n",
    "\n",
    "Create token from account section of kaggle and move file created to \n",
    "~/.kaggle/kaggle.json if locally or in /root if in Colab\n",
    "\n",
    "! mkdir ~/.kaggle (will create under /root/ if in Colab)\n",
    "! mv kaggle.json  /root/.kaggle\n",
    "! chmod 600 /root/.kaggle/kaggle.json or chmod 600 ~/.kaggle/kaggle.json if local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make sure you use the latest version of kaggle:\n",
    "!pip install --upgrade --force-reinstall --no-deps kaggle\n",
    "# with an older version, not all files get downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d rtatman/ubuntu-dialogue-corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data && unzip ubuntu-dialogue-corpus.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm ubuntu-dialogue-corpus.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chats Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since data has been split in multiple pickle files due to size, we load it this wa\n",
    "chats_datafiles = glob.glob(\"./data/Ubuntu-dialogue-corpus/dialogueText*.csv\")\n",
    "chats_df = pd.concat([pd.read_csv(fp) for fp in chats_datafiles], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chats_df.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chats_df.dropna(inplace=True)\n",
    "chats_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chats_df.shape)\n",
    "chats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(chats_df.date), max(chats_df.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ymd = pd.DatetimeIndex(chats_df['date'])\n",
    "#chats_df['year'] = ymd.year\n",
    "#chats_df['month'] = ymd.month\n",
    "#chats_df['day'] = ymd.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chats_df = chats_df.sort_values(['folder','dialogueID', 'date'])\n",
    "chats_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_to = chats_df[['from','to']].apply(lambda x: ' '.join(np.sort(x)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_to.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chats_df.drop(['folder', 'date', 'year', 'month', 'day'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talking Points Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A First Glance at Transcripts\n",
    "\n",
    "Is the discussed button a reliable label? \n",
    "\n",
    "i=0, wrongly tagged as discussed\n",
    "\n",
    "i=3 correct\n",
    "\n",
    "i=4 wrong\n",
    "\n",
    "i=7 correct\n",
    "\n",
    "Is Nexidia transcription accurate enough to capture the talking points or are there cases where the transcriptions missed those phrases?\n",
    "\n",
    "Am I merging Nexus and Nexidia correctly? It seems so since for some cases I see correct results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A First Glance at Chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chats_df.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "cT = chats_df.iloc[i]['Transcript']\n",
    "cT = cT.split('\\n')\n",
    "\n",
    "cT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Trained Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.sbert.net/docs/installation.html\n",
    "\n",
    "#these lines below are example for downloading pre-trained models\n",
    "#embed_bert = SentenceTransformer('paraphrase-xlm-r-multilingual-v1')\n",
    "#embed_bert = SentenceTransformer('stsb-roberta-large') #textual similarity\n",
    "\n",
    "#the models are downloaded to here\n",
    "#/Users/atambu310/.cache/torch/sentence_transformers/sbert.net_models_paraphrase-xlm-r-multilingual-v1_part\n",
    "#copy to desired folder, ex: ./models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of Using Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat sits outside \t\t The dog plays in the garden \t\t Score: 0.3065\n",
      "A man is playing guitar \t\t A woman watches TV \t\t Score: 0.2188\n",
      "The new movie is awesome \t\t The new movie is so great \t\t Score: 0.9821\n"
     ]
    }
   ],
   "source": [
    "# this is equivalent to Google Universal Sentence Encoder\n",
    "embed_bert = SentenceTransformer('./models/sbert.net_models_._distiluse-base-multilingual-cased-v2')\n",
    "\n",
    "# Two lists of sentences\n",
    "sentences1 = ['The cat sits outside',\n",
    "             'A man is playing guitar',\n",
    "             'The new movie is awesome']\n",
    "\n",
    "sentences2 = ['The dog plays in the garden',\n",
    "              'A woman watches TV',\n",
    "              'The new movie is so great']\n",
    "\n",
    "#Compute embedding for both lists\n",
    "embeddings1 = embed_bert.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = embed_bert.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "#Compute cosine-similarits\n",
    "cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "#Output the pairs with their score\n",
    "for i in range(len(sentences1)):\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences1[i], sentences2[i], cosine_scores[i][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97768307]], dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lower-casing or space removal are not needed with this model. Apparently, some preproc\n",
    "#is performed internally to the model\n",
    "\n",
    "util.pytorch_cos_sim(embed_bert.encode([\"With the Wifi Gateway, you'll get access to our simple and digital xFi dashboard.\"], convert_to_tensor=True), \n",
    "                     embed_bert.encode([\"with the wi-fi gateway, you will get access to our simple and digital xFi dashboard.\"], convert_to_tensor=True)).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Do you know who Emily Dickson is?'],\n",
       " ['Emily Dickinson?',\n",
       "  'The poet?',\n",
       "  'I do!',\n",
       "  '\"Tell all the truth, but tell it slant\" she once said.',\n",
       "  'Do you like her poetry?'],\n",
       " ['Yeah she was an icon she died in 1886 at the tender age of 55.'],\n",
       " ['Though she was reclusive, she lived an interesting 55 years.',\n",
       "  'Do you know much about her life?'],\n",
       " ['I did not unfortunately!',\n",
       "  'I hear over the years she shared at least 250 poems with Susan her close friend before marrying Austin.'],\n",
       " ['Yes.',\n",
       "  'she wrote hundreds and hundreds of poems, but they were locked away in a drawer, and a critic said that there were many arresting phrases, nothing scanned or rhymed properly, and so he declined to help get them published.'],\n",
       " ['Did you kow theres a poem when read normally is depressing but when read backward is uplifting?'],\n",
       " ['Wow!',\n",
       "  \"That is certainly different than Emily's poetry.\",\n",
       "  \"There's such a diversity in poetry.\",\n",
       "  \"It's no surprise, since poetry dates back to prehistorical times.\",\n",
       "  'Did you know some of the first poetry was hunting poetry in Africa?'],\n",
       " ['Yes and and extensively throughout the history of the empire of the Nile, Niger and Volta river valleys.'],\n",
       " ['Yes.',\n",
       "  'Some of the earliest written poetry in Africa is found among Pyramid texts, written during the 25th century, BCE!',\n",
       "  'Of course, poetry spread throughout the world, too.'],\n",
       " ['Wow i did not know that.',\n",
       "  'Edgar Allen Poe received 9.00 for the raven,can you believe that?'],\n",
       " ['Just $9?',\n",
       "  'You know, art, music, and poetry were once Olympic sports?',\n",
       "  'Can you imagine Edgar Allen Poe as an Olympian?'],\n",
       " ['I can not but the fact that those parts of our culture use to be in the Olympics is amazing.',\n",
       "  'They should bring that back.'],\n",
       " ['Yes, poetry does seem to have lost some respect.',\n",
       "  'In the past, the Vikings were warrior-poets, and poetry was considered a gift from Odin himself.'],\n",
       " [\"Now that's interesting.\", 'Homers Odyssey was one of my favorites.'],\n",
       " ['Ah yes!',\n",
       "  \"Quite an epic, isn't it?\",\n",
       "  'And Homer wrote the Iliad, as well.'],\n",
       " ['Bringing back so many memories, i think i might listen to that soon.',\n",
       "  'Demetri Martin wrote a 224 word palindrome poem.'],\n",
       " ['Funny!',\n",
       "  'You really can do so much with poetry!',\n",
       "  \"There's also a poem that's 274 lines, and features about 800 irregularly pronounced English words.\",\n",
       "  \"It's called The Chaos.\",\n",
       "  \"I'd like hear that one read out loud!\"],\n",
       " ['Yeah that seems like the right name for it.',\n",
       "  'Do you listen to or play the piano?'],\n",
       " ['Funny you should ask!',\n",
       "  'I was just going to ask if you knew that they used to call typewriters \"literary pianos\"!',\n",
       "  \"Isn't that funny?\",\n",
       "  'I like to bang on the keyboard every now and then!',\n",
       "  'What about you?'],\n",
       " [\"That's all i do is bang on them while missing the keys i'm aiming for, lol!\",\n",
       "  'Nice chatting with you.'],\n",
       " [\"Good thing you're not playing on an old steam piano!\",\n",
       "  \"They'd hear you for miles around!\",\n",
       "  'Goodbye!'],\n",
       " ['Well maybe not on Mars, haha, Goodbye.']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cT = [ic['message'] for ic in chats_df.iloc[0]['content']]\n",
    "cT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for ic in cT[:10]:\n",
    "    #print(ic)\n",
    "    for it in talking_points:\n",
    "        #print(it)\n",
    "        for icc in ic:\n",
    "            ic_it_dist = util.pytorch_cos_sim(embed_bert.encode([icc], convert_to_tensor=True), \n",
    "                                 embed_bert.encode([it], convert_to_tensor=True)).detach().cpu().numpy()\n",
    "            scores.append(float(ic_it_dist))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31129002571105957"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[158]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Emma Charlotte Duerre Watson (born 15 April 1990) is an English actress, model, and activist. Born in Paris and brought up in Oxfordshire, Watson attended the Dragon School and trained as an actress at the Oxford branch of Stagecoach Theatre Arts. As a child artist, she rose to prominence after landing her first professional acting role as Hermione Granger in the Harry Potter film series, having acted only in school plays previously. Watson appeared in all eight Harry Potter films from 2001 to 2011, earning worldwide fame, critical accolades, and around $60 million.Watson continued to work outside of the Harry Potter films, appearing in the 2007 television adaptation of the novel Ballet Shoes and lending her voice to The Tale of Despereaux (2008). Following the last Harry Potter film, she took on starring and supporting roles in My Week with Marilyn (2011), The Perks of Being a Wallflower (2012) and The Bling Ring (2013), made an appearance as an exaggerated version of herself in This Is the End (2013), and portrayed the title character's adopted daughter in Noah (2014). In 2017, she starred as Belle in a live-action adaptation of the musical romantic fantasy film Beauty and the Beast. Her other roles include Regression (2015), Colonia (2015) and The Circle (2017).\""
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talking_points[158]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3,
     18,
     37
    ]
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class processText:\n",
    "        \n",
    "    def __init__(self):\n",
    "        \n",
    "        import tensorflow as tf\n",
    "        import tensorflow_hub as hub\n",
    "        import tensorflow_text #needed to avoid crashes    \n",
    "        \n",
    "        self.texts = ray.get(texts_ray)\n",
    "        \n",
    "        print('loading model')\n",
    "        self.embed = SentenceTransformer('./models/sbert.net_models_._distiluse-base-multilingual-cased-v2')\n",
    "        print('loading model...done')\n",
    "\n",
    "        self.talking_points_emb = self.embed.encode(ray.get(talking_points_ray), convert_to_tensor=True)\n",
    "\n",
    "        \n",
    "    def clean_sentences(self, cT):\n",
    "\n",
    "        #create list of senteences from text\n",
    "        cT = re.sub(r'\\.\\.\\.','<UNK>', cT)\n",
    "        cT = re.sub(r'<UNK>','', cT)\n",
    "        cT = cT.split('\\n')\n",
    "                \n",
    "        cT = [s.lower() for s in cT] #lower case\n",
    "        cT = [\" \".join([w for w in s.split() if len(s.split())>5]) for s in cT]  #extra spaces, at least 5 words\n",
    "\n",
    "        if len(cT)==0:\n",
    "            return []\n",
    "\n",
    "        if len(cT)<3: # at least 3 sentences\n",
    "            return []\n",
    "        else:\n",
    "            return cT\n",
    "    \n",
    "    \n",
    "    def get_points(self, text_idxs, phrase_thr=0.60):\n",
    "\n",
    "        is_talking_points = {}\n",
    "        \n",
    "        print('start', text_idxs)\n",
    "        \n",
    "        for i in range(text_idxs[0], text_idxs[1]): \n",
    "            \n",
    "            cT = self.texts[i]\n",
    "            cT = self.clean_sentences(cT)\n",
    "            \n",
    "            if len(cT)==0:\n",
    "                continue\n",
    "\n",
    "            emb_cT_i = self.embed.encode(cT, convert_to_tensor=True)\n",
    "            # similarity \n",
    "            sim_mat = util.pytorch_cos_sim(emb_cT_i,\n",
    "                                           self.talking_points_emb).detach().cpu().numpy()\n",
    "            \n",
    "            # loop over individual sentences and check similarity to each of the phrases    \n",
    "            #best_match = np.unravel_index(np.argmax(sim_mat, axis=None), sim_mat.shape)\n",
    "            #best_match_value = sim_mat[best_match]\n",
    "            #if best_match_value>phrase_thr:\n",
    "            #    is_talking_points.update({(i,cT[best_match[0]]): [(best_match[1], best_match_value)]})\n",
    "            \n",
    "            # for each sentence find matching phrases above threshold. \n",
    "            # In a chat mutiple talking points can be mentioned\n",
    "            for j in range(sim_mat.shape[0]):\n",
    "                sim_idx = np.where(sim_mat[j,]>phrase_thr)[0]\n",
    "                sim_values = [(k, sim_mat[j,k]) for k in sim_idx] # this is for debugging purposes, later just select best matching phrase\n",
    "                if len(sim_idx)>0:\n",
    "                    is_talking_points.update({(i,cT[j]): sim_values})\n",
    "            \n",
    "\n",
    "        print('end', text_idxs)\n",
    "        \n",
    "        return is_talking_points\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Call Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "num_cpus = psutil.cpu_count(logical=False)\n",
    "max_calls = 10000#len(calls_df['Transcript'].tolist())\n",
    "n_cells = 50 #to run in a single process\n",
    "\n",
    "print('Processing', max_calls, 'calls')\n",
    "\n",
    "# split task into chunks\n",
    "run_list_chnks = np.linspace(0, max_calls, int(max_calls/n_cells), dtype=int)\n",
    "run_list_chnks = [(run_list_chnks[i],run_list_chnks[i+1]) for i in range(0,len(run_list_chnks)-1)]\n",
    "\n",
    "# init ray\n",
    "ray.init(num_cpus=num_cpus)\n",
    "#ray.timeline(filename=\"./timeline.json\") #debugging\n",
    "\n",
    "phrase_thr = 0.50\n",
    "\n",
    "texts_ray = ray.put(calls_df['Transcript'].tolist()[:max_calls])\n",
    "talking_points_ray = ray.put(talking_points)\n",
    "\n",
    "pT = [processText.remote() for _ in range(num_cpus)]\n",
    "\n",
    "# every 'num_cpus' jobs, start from worker 0 again\n",
    "result_ids = [pT[i % num_cpus].get_points.remote(run_list_chnks[i],\n",
    "                                                 phrase_thr=phrase_thr) for i in range(len(run_list_chnks))] \n",
    "\n",
    "# Fetch the results.\n",
    "#results = ray.get(result_ids)    \n",
    "results = ray.get(result_ids)    \n",
    "\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of Processed Transcript Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0] # (transcript index, utterance text above threshold): [(talking point 1, similarity to utterance),(talking point 2, similarity to utterance)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "talking_points[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "num_cpus = psutil.cpu_count(logical=False)\n",
    "max_chats = 10000# len(chats_df['Transcript'].tolist())\n",
    "n_cells = 50 #to run in a single process\n",
    "\n",
    "print('Processing', max_chats, 'chats')\n",
    "\n",
    "# split task into chunks\n",
    "run_list_chnks = np.linspace(0, max_chats, int(max_chats/n_cells), dtype=int)\n",
    "run_list_chnks = [(run_list_chnks[i],run_list_chnks[i+1]) for i in range(0,len(run_list_chnks)-1)]\n",
    "\n",
    "# init ray\n",
    "ray.init(num_cpus=num_cpus)\n",
    "\n",
    "phrase_thr = 0.50\n",
    "\n",
    "texts_ray = ray.put(chats_df['Transcript'].tolist()[:max_chats])\n",
    "talking_points_ray = ray.put(talking_points)\n",
    "\n",
    "pT = [processText.remote() for _ in range(num_cpus)]\n",
    "\n",
    "# every 'num_cpus' jobs, start from worker 0 again\n",
    "result_ids = [pT[i % num_cpus].get_points.remote(run_list_chnks[i],\n",
    "                                                 phrase_thr=phrase_thr) for i in range(len(run_list_chnks))] \n",
    "\n",
    "# Fetch the results.\n",
    "#results = ray.get(result_ids)    \n",
    "results_c = ray.get(result_ids)\n",
    "\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of Processed Chat Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_c[0] # (transcript index, utterance text above threshold): [(talking point 1, similarity to utterance),(talking point 2, similarity to utterance)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "talking_points[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Processed Data\n",
    "\n",
    "For each talking point in the table below, we randomly sample few transcript extracts to check reliability of extract retrieval approach used in this notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def analyze_results(results, n_texts, phrase_thr, verbose=True):\n",
    "\n",
    "    talking_points_cnts = {k: 0 for k in talking_points}\n",
    "\n",
    "    # loop over processed chunks and extract statistics\n",
    "    for rr in range(len(results)):\n",
    "        for chat_no_extract,tp_no_sim in results[rr].items():\n",
    "            chat_no, chat_extract = chat_no_extract[0], chat_no_extract[1]\n",
    "            tp_no_sim_sorted = sorted(tp_no_sim, key=lambda x: x[1], reverse=True) # sort by similarity values\n",
    "            for kk in tp_no_sim_sorted[:1]: # take best\n",
    "                tp_no = kk[0]\n",
    "                tp_sim = kk[1]\n",
    "                if tp_sim>phrase_thr:\n",
    "                    if verbose:\n",
    "                        print('------> Chat no. ', chat_no, 'Type: ', df.chatQueueLob[chat_no])\n",
    "                        print('---> Extract:', chat_extract)\n",
    "                        print('---> Phrase ', talking_points[tp_no])\n",
    "                        print('---> Similarity index', tp_sim)\n",
    "                    talking_points_cnts[talking_points[tp_no]] += 1\n",
    "                 \n",
    "    #extract some examples of match\n",
    "    sample_extracts = {tp: [] for tp in talking_points}\n",
    "    for tp in talking_points:\n",
    "        for rr in range(len(results)):\n",
    "            for chat_no_extract, tp_no_sim in results[rr].items():\n",
    "                chat_no, chat_extract = chat_no_extract[0], chat_no_extract[1]\n",
    "                tp_no_sim_sorted = sorted(tp_no_sim, key=lambda x: x[1], reverse=True)\n",
    "                for kk in tp_no_sim_sorted[:1]: # take best\n",
    "                    tp_no = kk[0]\n",
    "                    tp_sim = kk[1]\n",
    "                    if tp_sim>phrase_thr and tp_no==talking_points.index(tp):\n",
    "                        sample_extracts[tp].append('**' + chat_extract)\n",
    "                        #print('----->', tp)\n",
    "                        #print('---> Extract:', chat_extract)\n",
    "        if verbose:\n",
    "            print(tp, len(sample_extracts[tp]), len(sample(sample_extracts[tp],min(20, len(sample_extracts[tp])))))\n",
    "        sample_extracts[tp] = '\\n'.join(sample(sample_extracts[tp],min(20, len(sample_extracts[tp])))) # sample only 5 examples\n",
    "        #sample_extracts[tp] = '\\n'.join(sample_extracts[tp]) # sample only 5 examples\n",
    "    sample_extracts = [v for k,v in sample_extracts.items()]\n",
    "    \n",
    "    ## put in excel\n",
    "    results_df = pd.DataFrame({'Talking Points': [k for k,v  in talking_points_cnts.items()], \n",
    "                  'Perc. Used': [100*v/n_texts for k,v  in talking_points_cnts.items()],\n",
    "                  'Sample Extracts': sample_extracts,\n",
    "                  'Human Corrected': [0 for k in talking_points_cnts]})# randomly sample 20 extracts for each talking point and visually inspect how many are right\n",
    "\n",
    "    results_df.to_excel('extracts.xlsx')\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = analyze_results(results, max_chats, phrase_thr=0.6, verbose=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 5\n",
    "results_df.iloc[i,0], results_df.iloc[i,2].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 6\n",
    "results_df.iloc[i,0], results_df.iloc[i,2].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 19\n",
    "results_df.iloc[i,0], results_df.iloc[i,2].split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_c_df = analyze_results(results_c, max_chats, phrase_thr=0.6, verbose=False)\n",
    "results_c_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "results_c_df.iloc[i,0], results_c_df.iloc[i,2].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 7\n",
    "results_c_df.iloc[i,0], results_c_df.iloc[i,2].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "embed = SentenceTransformer('./models/sbert.net_models_._distiluse-base-multilingual-cased-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "talking_points_emb = embed.encode(talking_points, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# input text gets extra slash in front of \\n, so we added \\\\n for splitting sentences\n",
    "def clean_sentences(cT):\n",
    "\n",
    "        #create list of senteences from text\n",
    "        cT = re.sub(r'\\.\\.\\.','<UNK>', cT)\n",
    "        cT = re.sub(r'<UNK>','', cT)\n",
    "        cT = cT.split('\\\\n')\n",
    "                \n",
    "        cT = [s.lower() for s in cT] #lower case\n",
    "        cT = [\" \".join([w for w in s.split() if len(s.split())>5]) for s in cT]  #extra spaces, at least 5 words\n",
    "\n",
    "        if len(cT)==0:\n",
    "            return []\n",
    "\n",
    "        if len(cT)<3: # at least 3 sentences\n",
    "            return []\n",
    "        else:\n",
    "            return cT\n",
    "    \n",
    "    \n",
    "def get_points(cT, phrase_thr=0.60):\n",
    "\n",
    "        cT = clean_sentences(cT)\n",
    "            \n",
    "        if len(cT)==0:\n",
    "            return ''\n",
    "        \n",
    "        emb_cT = embed.encode(cT, convert_to_tensor=True)\n",
    "        # similarity \n",
    "        sim_mat = util.pytorch_cos_sim(emb_cT,\n",
    "                                       talking_points_emb).detach().cpu().numpy()\n",
    "            \n",
    "        # for each sentence find matching phrases above threshold. \n",
    "        for j in range(sim_mat.shape[0]):\n",
    "            sim_idx = np.where(sim_mat[j,]>phrase_thr)[0]\n",
    "            sim_values = [(k, sim_mat[j,k]) for k in sim_idx] \n",
    "            sim_sorted = sorted(sim_values, key=lambda x: x[1], reverse=True) # sort by similarity values\n",
    "            if len(sim_sorted)>0:\n",
    "                print('**utterance:', cT[j])\n",
    "                print('Talking Point:', talking_points[sim_sorted[0][0]])\n",
    "                print('Similarity: ', sim_sorted[0][1])            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('**Available talking points**')\n",
    "print('')\n",
    "for i in talking_points:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Chats\n",
    "i=185 #11, 185, 2010, 2334\n",
    "chats_df['Transcript'].iloc[i]\n",
    "#Calls\n",
    "#i=1460 #856, 865, 1460\n",
    "#calls_df['Transcript'].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@interact_manual(in_text='', phrase_thr=widgets.FloatSlider(min=0.5, max=0.8, step=0.1, value=0.5))\n",
    "def g(in_text, phrase_thr):\n",
    "    return get_points(in_text, phrase_thr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## add pop-up message saying if talking point is pressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Contents](#Table-of-Contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
